{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033bbd33",
   "metadata": {},
   "source": [
    "# TopicAnalyser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5ba13",
   "metadata": {},
   "source": [
    "For those curious about Data Science, jupyter notebooks are an essential part of experimentation. You can quickly test out different AI/ML models on different data. Feel free to experiment with different methods of topic analysis here, or try with different data here. Consider making your experimented code available in TopicAnalyser.py, and part of your API in main.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53aaef96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-18T15:03:26.876663Z",
     "start_time": "2022-03-18T15:03:07.219870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic 0:\n",
      "reduced significantly overhaul strategic capital db strength leverage market exposure\n",
      "Topic 1:\n",
      "bank ratings deutsche upgrade moody placed upgrades outlook performance agency\n",
      "Topic 2:\n",
      "revenue businesses bank market segments global attrition areas good added\n",
      "Topic 3:\n",
      "upgrade key finance credit db debt deutsche diversified earnings equity\n",
      "Topic 4:\n",
      "cost sustained db achieve leverage restructuring operating equity attrition billion\n",
      "Topic 5:\n",
      "risk db billion unsecured half debt diversified asset segments exposure\n",
      "Topic 6:\n",
      "progress deutsche bank new activities transforming officer added ago chief\n",
      "Topic 7:\n",
      "business cost half transforming chief model officer sustainable great profit\n",
      "Topic 8:\n",
      "sustainable ahead targets bank finance key deutsche db moody goals\n",
      "Topic 9:\n",
      "bank markets base capital db substantial sound profit strengths ago\n",
      "Topic 10:\n",
      "revenue core capital db restructuring model strengths ahead growing goals\n",
      "Topic 11:\n",
      "capital bank credit good noted rating sound substantial equity asset\n",
      "Topic 12:\n",
      "rating term ratings deutsche bank unsecured debt long short positive\n",
      "Topic 13:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "Topic 14:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "Topic 15:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "Topic 16:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "Topic 17:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "Topic 18:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "Topic 19:\n",
      "upgrades liquidity costs credit db debt deutsche diversified earnings equity\n",
      "/home/s_sharan9/.local/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/s_sharan9/.local/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:1477: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "# dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "# documents = dataset.data\n",
    "# print(documents)\n",
    "documents = []\n",
    "with open('../frontend_notebook/articles/article1.txt') as f:\n",
    "    documents = f.readlines()\n",
    "\n",
    "# print(\"*\" * 25)\n",
    "# print(documents)\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# # LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "# tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "# tf = tf_vectorizer.fit_transform(documents)\n",
    "# tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 20\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "# lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "# display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ac2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.9.2 64-bit",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}